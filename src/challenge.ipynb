{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este archivo puedes escribir lo que estimes conveniente. Te recomendamos detallar tu solución y todas las suposiciones que estás considerando. Aquí puedes ejecutar las funciones que definiste en los otros archivos de la carpeta src, medir el tiempo, memoria, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"data/farmers-protest-tweets-2021-2-4.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En caso de que el archivo sea muchísimo más grande, este tipo de funciones iterativas deja de ser tan óptimo, por lo que podría pensarse en el uso de (Py)Spark. \n",
    "\n",
    "Usualmente en algún job de dataproc con un cluster efímero que permita el procesamiento distribuído de la data y posible carga a Bigquery por ejemplo.\n",
    "\n",
    "O, si tenemos información que llega en Streaming, podría pensarse en el uso de Dataflow con Apache Beam."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importación de las librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The memory_profiler extension is already loaded. To reload it, use:\n",
      "  %reload_ext memory_profiler\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import ujson\n",
    "from collections import defaultdict, Counter\n",
    "from datetime import datetime\n",
    "from typing import List, Tuple, Optional\n",
    "from pydantic import BaseModel, ValidationError, field_validator\n",
    "import emoji\n",
    "import regex\n",
    "\n",
    "\n",
    "%load_ext memory_profiler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validador de esquema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Antes de iniciar con el desarrollo de las lógicas asociadas a la solución de los retos, considero fundamental validar el esquema del Json que se espera procesar. En este caso se usa Pydantic para valdiar los types y la existencia de los objetos y sub objetos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DescriptionUrlModel(BaseModel):\n",
    "    \"\"\"\n",
    "    Modelo que representa una URL de descripción dentro de un tweet.\n",
    "\n",
    "    Attributes:\n",
    "        text (str): El texto de la URL.\n",
    "        indices (List[int]): Lista de índices que indican la posición de la URL en el texto del tweet.\n",
    "    \"\"\"\n",
    "\n",
    "    text: str\n",
    "    indices: List[int]\n",
    "\n",
    "class UserModel(BaseModel):\n",
    "    \"\"\"\n",
    "    Modelo que representa un usuario de Twitter.\n",
    "\n",
    "    Attributes:\n",
    "        username (str): El nombre de usuario de Twitter.\n",
    "        displayname (Optional[str]): El nombre de pantalla del usuario.\n",
    "        id (int): El ID del usuario.\n",
    "        description (Optional[str]): La descripción del usuario.\n",
    "        rawDescription (Optional[str]): La descripción cruda del usuario.\n",
    "        descriptionUrls (Optional[List[DescriptionUrlModel]]): Lista de URLs en la descripción del usuario.\n",
    "        verified (Optional[bool]): Indicador de si el usuario está verificado.\n",
    "        created (Optional[str]): La fecha de creación de la cuenta del usuario.\n",
    "        followersCount (Optional[int]): La cantidad de seguidores del usuario.\n",
    "        friendsCount (Optional[int]): La cantidad de amigos del usuario.\n",
    "        statusesCount (Optional[int]): La cantidad de estados del usuario.\n",
    "        favouritesCount (Optional[int]): La cantidad de favoritos del usuario.\n",
    "        listedCount (Optional[int]): La cantidad de listas en las que aparece el usuario.\n",
    "        mediaCount (Optional[int]): La cantidad de medios publicados por el usuario.\n",
    "        location (Optional[str]): La ubicación del usuario.\n",
    "        protected (Optional[bool]): Indicador de si la cuenta del usuario está protegida.\n",
    "        linkUrl (Optional[str]): URL del perfil del usuario.\n",
    "        linkTcourl (Optional[str]): URL acortada del perfil del usuario.\n",
    "        profileImageUrl (Optional[str]): URL de la imagen del perfil del usuario.\n",
    "        profileBannerUrl (Optional[str]): URL del banner del perfil del usuario.\n",
    "        url (Optional[str]): URL del usuario.\n",
    "    \"\"\"\n",
    "\n",
    "    username: str\n",
    "    displayname: Optional[str] = None\n",
    "    id: int\n",
    "    description: Optional[str] = None\n",
    "    rawDescription: Optional[str] = None\n",
    "    descriptionUrls: Optional[List[DescriptionUrlModel]] = None\n",
    "    verified: Optional[bool] = None\n",
    "    created: Optional[str] = None\n",
    "    followersCount: Optional[int] = None\n",
    "    friendsCount: Optional[int] = None\n",
    "    statusesCount: Optional[int] = None\n",
    "    favouritesCount: Optional[int] = None\n",
    "    listedCount: Optional[int] = None\n",
    "    mediaCount: Optional[int] = None\n",
    "    location: Optional[str] = None\n",
    "    protected: Optional[bool] = None\n",
    "    linkUrl: Optional[str] = None\n",
    "    linkTcourl: Optional[str] = None\n",
    "    profileImageUrl: Optional[str] = None\n",
    "    profileBannerUrl: Optional[str] = None\n",
    "    url: Optional[str] = None\n",
    "\n",
    "class TweetModel(BaseModel):\n",
    "    \"\"\"\n",
    "    Modelo que representa un tweet.\n",
    "\n",
    "    Attributes:\n",
    "        url (str): URL del tweet.\n",
    "        date (str): Fecha y hora del tweet en formato ISO 8601.\n",
    "        content (Optional[str]): Contenido del tweet.\n",
    "        renderedContent (Optional[str]): Contenido renderizado del tweet.\n",
    "        id (int): ID del tweet.\n",
    "        user (UserModel): Información del usuario que publicó el tweet.\n",
    "        outlinks (Optional[List[str]]): Lista de URLs externas incluidas en el tweet.\n",
    "        tcooutlinks (Optional[List[str]]): Lista de URLs acortadas incluidas en el tweet.\n",
    "        replyCount (Optional[int]): Cantidad de respuestas al tweet.\n",
    "        retweetCount (Optional[int]): Cantidad de retweets del tweet.\n",
    "        likeCount (Optional[int]): Cantidad de \"me gusta\" del tweet.\n",
    "        quoteCount (Optional[int]): Cantidad de citas del tweet.\n",
    "        conversationId (Optional[int]): ID de la conversación a la que pertenece el tweet.\n",
    "        lang (Optional[str]): Idioma del tweet.\n",
    "        source (Optional[str]): Fuente desde donde se publicó el tweet.\n",
    "        sourceUrl (Optional[str]): URL de la fuente desde donde se publicó el tweet.\n",
    "        sourceLabel (Optional[str]): Etiqueta de la fuente desde donde se publicó el tweet.\n",
    "        media (Optional[List[dict]]): Lista de medios adjuntos al tweet.\n",
    "        retweetedTweet (Optional[dict]): Información del tweet retuiteado, si aplica.\n",
    "        quotedTweet (Optional[dict]): Información del tweet citado, si aplica.\n",
    "        mentionedUsers (Optional[List[UserModel]]): Lista de usuarios mencionados en el tweet.\n",
    "    \"\"\"\n",
    "\n",
    "    url: str\n",
    "    date: str\n",
    "    content: Optional[str] = None\n",
    "    renderedContent: Optional[str] = None\n",
    "    id: int\n",
    "    user: UserModel\n",
    "    outlinks: Optional[List[str]] = None\n",
    "    tcooutlinks: Optional[List[str]] = None\n",
    "    replyCount: Optional[int] = None\n",
    "    retweetCount: Optional[int] = None\n",
    "    likeCount: Optional[int] = None\n",
    "    quoteCount: Optional[int] = None\n",
    "    conversationId: Optional[int] = None\n",
    "    lang: Optional[str] = None\n",
    "    source: Optional[str] = None\n",
    "    sourceUrl: Optional[str] = None\n",
    "    sourceLabel: Optional[str] = None\n",
    "    media: Optional[List[dict]] = None\n",
    "    retweetedTweet: Optional[dict] = None\n",
    "    quotedTweet: Optional[dict] = None\n",
    "    mentionedUsers: Optional[List[UserModel]] = None\n",
    "\n",
    "    @field_validator('date')\n",
    "    def validate_date_format(cls, value):\n",
    "        \"\"\"\n",
    "        Valida que la fecha esté en el formato ISO 8601 correcto.\n",
    "\n",
    "        Args:\n",
    "            value (str): La fecha en formato de cadena.\n",
    "\n",
    "        Returns:\n",
    "            str: La fecha validada.\n",
    "\n",
    "        Raises:\n",
    "            ValueError: Si la fecha no está en el formato correcto.\n",
    "        \"\"\"\n",
    "\n",
    "        try:\n",
    "            datetime.strptime(value, \"%Y-%m-%dT%H:%M:%S%z\")\n",
    "        except ValueError:\n",
    "            raise ValueError(\"Incorrect date format\")\n",
    "        return value\n",
    "\n",
    "def validate_tweet(tweet: dict) -> bool:\n",
    "    \"\"\"\n",
    "    Valida que un diccionario de tweet cumpla con el esquema definido por TweetModel.\n",
    "\n",
    "    Args:\n",
    "        tweet (dict): Diccionario que representa el tweet.\n",
    "\n",
    "    Returns:\n",
    "        bool: True si el tweet es válido, False si no lo es.\n",
    "\n",
    "    Raises:\n",
    "        ValidationError: Si el tweet no cumple con el esquema.\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        TweetModel(**tweet)\n",
    "        return True\n",
    "    except ValidationError as e:\n",
    "        print(f\"Validation error: {e}\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Top 10 fechas donde hay más tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## q1_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Desarrollo de la función"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La función q1_time está optimizada para ser rápida en términos de tiempo de ejecución. Utiliza el módulo ujson (UltraJSON) para la lectura y decodificación de los datos JSON, lo cual es significativamente más rápido que el módulo json estándar de Python.\n",
    "\n",
    "Cómo logra la optimización en tiempo\n",
    "* **Lectura Rápida de Datos:**\n",
    "Utiliza ujson.loads en lugar de json.loads, lo que reduce el tiempo de decodificación de los datos JSON.\n",
    "* **Procesamiento Eficiente de Datos:**\n",
    "Procesa los datos de manera eficiente con un único bucle para contar los tweets por usuario y fecha.\n",
    "* **Uso de Estructuras de Datos Adecuadas:**\n",
    "Utiliza defaultdict y Counter para gestionar y contar los tweets de manera eficiente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimización por tiempo\n",
    "def q1_time(file_path: str) -> List[Tuple[datetime, str]]:\n",
    "    \"\"\"\n",
    "    Procesa un archivo JSON línea por línea, analiza los tweets contenidos en él\n",
    "    y devuelve una lista con las 10 fechas con más tweets y el usuario que más tweets\n",
    "    publicó en cada una de esas fechas.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): La ruta al archivo JSON que contiene los tweets. Cada línea del archivo\n",
    "                         debe ser un objeto JSON que representa un tweet.\n",
    "\n",
    "    Returns:\n",
    "        List[Tuple[datetime.date, str]]: Una lista de tuplas, donde cada tupla contiene una fecha\n",
    "                                         y el nombre de usuario del usuario que más tweets publicó\n",
    "                                         en esa fecha. La lista está ordenada por la cantidad de tweets\n",
    "                                         en orden descendente, incluyendo solo las 10 fechas principales.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Se usa ujson para la lectura del archivo\n",
    "    with open(file_path, 'r') as file:\n",
    "        data = [ujson.loads(line) for line in file]\n",
    "    \n",
    "    # Contador para rastrear la cantidad de tweets por usuario en cada fecha\n",
    "    date_user_count = defaultdict(lambda: Counter())\n",
    "    \n",
    "    for tweet in data:\n",
    "        # Validación del schema\n",
    "        if not validate_tweet(tweet):\n",
    "            continue\n",
    "\n",
    "        # Extraer la fecha del tweet y convertirla a un objeto de fecha\n",
    "        date = datetime.strptime(tweet[\"date\"], \"%Y-%m-%dT%H:%M:%S%z\").date()\n",
    "\n",
    "        # Extraer el nombre de usuario del tweet\n",
    "        user = tweet[\"user\"][\"username\"]\n",
    "\n",
    "        # Incrementar el contador para el usuario en la fecha correspondiente\n",
    "        date_user_count[date][user] += 1\n",
    "    \n",
    "    # Ordenar por cantidad de tweets y obtener las 10 fechas principales\n",
    "    top_dates = sorted(date_user_count.items(), key=lambda x: sum(x[1].values()), reverse=True)[:10]\n",
    "    \n",
    "    # Obtener el usuario con más publicaciones en cada fecha\n",
    "    result = [(date, user_count.most_common(1)[0][0]) for date, user_count in top_dates]\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test y evaluación\n",
    "\n",
    "Revisión de los resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q1_time(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Medición de tiempo promedio con su derivación estandard para 7 ejecuciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit q1_time(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Medición de la memoria usada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%memit q1_time(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## q1_memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Desarrollo de la función"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La función q1_memory está optimizada para utilizar menos memoria en comparación con una implementación estándar. Aunque no usa técnicas avanzadas de reducción de memoria, se asegura de que la memoria utilizada sea eficiente y no excesiva.\n",
    "\n",
    "Cómo logra la optimización en memoria\n",
    "* **Lectura y Decodificación Controlada:**\n",
    "Lee y decodifica el archivo JSON línea por línea para evitar cargar el archivo completo en memoria a la vez.\n",
    "* **Gestión Eficiente de Contadores:**\n",
    "Utiliza defaultdict y Counter para rastrear el número de tweets por usuario y fecha, lo que ayuda a mantener un uso de memoria controlado.\n",
    "* **Optimización de la Estructura de Datos:**\n",
    "La estructura de los contadores asegura que solo se almacene la información necesaria para el análisis, minimizando el uso de memoria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimización por memoria\n",
    "def q1_memory(file_path: str) -> List[Tuple[datetime, str]]:\n",
    "    \"\"\"\n",
    "    Procesa un archivo JSON línea por línea, analiza los tweets contenidos en él\n",
    "    y devuelve una lista con las 10 fechas con más tweets y el usuario que más tweets\n",
    "    publicó en cada una de esas fechas. Esta implementación está optimizada para el\n",
    "    uso eficiente de memoria.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): La ruta al archivo JSON que contiene los tweets. Cada línea del archivo\n",
    "                         debe ser un objeto JSON que representa un tweet.\n",
    "\n",
    "    Returns:\n",
    "        List[Tuple[datetime.date, str]]: Una lista de tuplas, donde cada tupla contiene una fecha\n",
    "                                         y el nombre de usuario del usuario que más tweets publicó\n",
    "                                         en esa fecha. La lista está ordenada por la cantidad de tweets\n",
    "                                         en orden descendente, incluyendo solo las 10 fechas principales.\n",
    "    \"\"\"\n",
    "\n",
    "    # Contador para rastrear la cantidad de tweets por usuario en cada fecha\n",
    "    date_user_count = defaultdict(Counter)\n",
    "\n",
    "    # Leer el archivo línea por línea y procesar cada tweet\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            tweet = json.loads(line)  # Usar ujson para la carga rápida de JSON\n",
    "            if not validate_tweet(tweet):  # Validar el esquema del tweet\n",
    "                continue\n",
    "            date = datetime.strptime(tweet[\"date\"], \"%Y-%m-%dT%H:%M:%S%z\").date()  # Convertir la fecha a objeto de fecha\n",
    "            user = tweet[\"user\"][\"username\"]  # Obtener el nombre de usuario\n",
    "            date_user_count[date][user] += 1  # Incrementar el contador para el usuario en la fecha correspondiente\n",
    "\n",
    "    # Ordenar por cantidad de tweets y obtener las 10 fechas principales\n",
    "    top_dates = sorted(date_user_count.items(), key=lambda x: sum(x[1].values()), reverse=True)[:10]\n",
    "    \n",
    "    # Obtener el usuario con más publicaciones en cada fecha\n",
    "    result = [(date, user_count.most_common(1)[0][0]) for date, user_count in top_dates]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test y evaluación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Revisión de los resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q1_memory(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Medición de tiempo promedio con su derivación estandard para 7 ejecuciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit q1_memory(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Medición de la memoria usada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%memit q1_memory(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparación de resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Función     | Tiempo de Ejecución             | Memoria Máxima (peak) | \n",
    "|-------------|---------------------------------|-----------------------|\n",
    "| `q1_time`   | 9.72 s ± 114 ms per loop        | 1338.06 MiB           |\n",
    "| `q1_memory` | 11.9 s ± 151 ms per loop        | 142.88 MiB            |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Top 10 emojis más usados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## q2_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Desarrollo de la función"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La función q2_time procesa un archivo JSON que contiene tweets para contar los emojis más usados de una manera eficiente en términos de tiempo. Los pasos son los siguientes:\n",
    "\n",
    "* **Lectura del Archivo:**\n",
    "\n",
    "Se abre el archivo especificado por file_path.\n",
    "Se lee todo el contenido del archivo y se convierte cada línea en un objeto JSON usando ujson.loads(line).\n",
    "\n",
    "* **Procesamiento de los Tweets:**\n",
    "\n",
    "Se itera sobre cada tweet.\n",
    "Se valida el esquema del tweet usando una función validate_tweet. Si el tweet no es válido, se salta.\n",
    "Se obtiene el contenido del tweet y se extraen los emojis usando la función extract_emojis.\n",
    "Se actualiza un contador (emoji_count) con los emojis encontrados.\n",
    "\n",
    "* **Obtención de los Emojis más Comunes:**\n",
    "\n",
    "Se obtienen los 10 emojis más comunes usando emoji_count.most_common(10).\n",
    "La función devuelve esta lista de los emojis más usados junto con sus conteos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "emoji_pattern = regex.compile(r'\\X')\n",
    "\n",
    "def extract_emojis(text):\n",
    "    \"\"\"\n",
    "    Extrae todos los emojis de un texto dado utilizando una expresión regular,\n",
    "    excluyendo los modificadores de tono de piel.\n",
    "\n",
    "    Args:\n",
    "        text (str): El texto del cual extraer emojis.\n",
    "\n",
    "    Returns:\n",
    "        List[str]: Una lista de emojis encontrados en el texto, sin los modificadores de tono de piel.\n",
    "    \"\"\"\n",
    "    emojis = [word for word in emoji_pattern.findall(text) if any(char in emoji.EMOJI_DATA for char in word)]\n",
    "    return emojis\n",
    "\n",
    "def q2_time(file_path: str) -> List[Tuple[str, int]]:\n",
    "    \"\"\"\n",
    "    Procesa un archivo JSON línea por línea, analiza el contenido de los tweets\n",
    "    y devuelve una lista con los 10 emojis más usados y su respectivo conteo.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): La ruta al archivo JSON que contiene los tweets. Cada línea del archivo\n",
    "                         debe ser un objeto JSON que representa un tweet.\n",
    "\n",
    "    Returns:\n",
    "        List[Tuple[str, int]]: Una lista de tuplas, donde cada tupla contiene un emoji y su conteo.\n",
    "                               La lista está ordenada por conteo en orden descendente, incluyendo solo los 10 emojis principales.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Leer y procesar el archivo en una sola pasada para mejorar la eficiencia\n",
    "    with open(file_path, 'r') as file:\n",
    "        data = [ujson.loads(line) for line in file]\n",
    "\n",
    "    emoji_count = Counter()\n",
    "\n",
    "    for tweet in data:\n",
    "        if not validate_tweet(tweet):\n",
    "            continue\n",
    "\n",
    "        content = tweet.get(\"content\", \"\")\n",
    "        emojis = extract_emojis(content)\n",
    "        emoji_count.update(emojis)\n",
    "        \n",
    "    result = emoji_count.most_common(10)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test y evaluación\n",
    "\n",
    "Revisión de los resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('🙏', 5049),\n",
       " ('😂', 3072),\n",
       " ('🚜', 2972),\n",
       " ('🌾', 2182),\n",
       " ('🤣', 1668),\n",
       " ('✊', 1642),\n",
       " ('❤️', 1382),\n",
       " ('🙏🏻', 1317),\n",
       " ('💚', 1040),\n",
       " ('👇', 873)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q2_time(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Medición de tiempo promedio con su derivación estandard para 7 ejecuciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24.3 s ± 238 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit q2_time(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Medición de la memoria usada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 1346.95 MiB, increment: 1228.37 MiB\n"
     ]
    }
   ],
   "source": [
    "%memit q2_time(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## q2_memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Desarrollo de la función"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La función q2_memory también procesa un archivo JSON que contiene tweets para contar los emojis más usados, pero está optimizada para un uso eficiente de la memoria. Los pasos son los siguientes:\n",
    "\n",
    "* **Lectura del Archivo:**\n",
    "\n",
    "Se abre el archivo especificado por file_path.\n",
    "En lugar de cargar todo el archivo en memoria de una vez, se lee línea por línea.\n",
    "\n",
    "* **Procesamiento de los Tweets:**\n",
    "\n",
    "Para cada línea del archivo, se convierte la línea en un objeto JSON usando json.loads(line).\n",
    "Se valida el esquema del tweet usando una función validate_tweet. Si el tweet no es válido, se salta.\n",
    "Se obtiene el contenido del tweet y se extraen los emojis directamente dentro de la función usando una versión interna de extract_emojis.\n",
    "Se actualiza un contador (emoji_count) con los emojis encontrados.\n",
    "\n",
    "* **Obtención de los Emojis más Comunes:**\n",
    "\n",
    "Se obtienen los 10 emojis más comunes usando emoji_count.most_common(10).\n",
    "La función devuelve esta lista de los emojis más usados junto con sus conteos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def q2_memory(file_path: str) -> List[Tuple[str, int]]:\n",
    "    \"\"\"\n",
    "    Procesa un archivo JSON línea por línea, analiza el contenido de los tweets\n",
    "    y devuelve una lista con los 10 emojis más usados y su respectivo conteo.\n",
    "    Esta implementación está optimizada para el uso eficiente de memoria.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): La ruta al archivo JSON que contiene los tweets. Cada línea del archivo\n",
    "                         debe ser un objeto JSON que representa un tweet.\n",
    "\n",
    "    Returns:\n",
    "        List[Tuple[str, int]]: Una lista de tuplas, donde cada tupla contiene un emoji y su conteo.\n",
    "                               La lista está ordenada por conteo en orden descendente, incluyendo solo los 10 emojis principales.\n",
    "    \"\"\"\n",
    "    emoji_count = Counter()\n",
    "\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            tweet = json.loads(line)\n",
    "            if not validate_tweet(tweet):  # Validar el esquema del tweet\n",
    "                continue\n",
    "            content = tweet.get(\"content\", \"\")\n",
    "            \n",
    "            emoji_list = []\n",
    "            data = regex.findall(r'\\X', content)\n",
    "            for word in data:\n",
    "                if any(char in emoji.EMOJI_DATA  for char in word):\n",
    "                    emoji_list.append(word)\n",
    "\n",
    "            emoji_count.update(emoji_list)\n",
    "\n",
    "    top_emojis = emoji_count.most_common(10)\n",
    "    return top_emojis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test y evaluación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Revisión de los resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('🙏', 5049),\n",
       " ('😂', 3072),\n",
       " ('🚜', 2972),\n",
       " ('🌾', 2182),\n",
       " ('🤣', 1668),\n",
       " ('✊', 1642),\n",
       " ('❤️', 1382),\n",
       " ('🙏🏻', 1317),\n",
       " ('💚', 1040),\n",
       " ('👇', 873)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q2_memory(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Medición de tiempo promedio con su derivación estandard para 7 ejecuciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26.6 s ± 167 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit q2_memory(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Medición de la memoria usada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 120.07 MiB, increment: 0.01 MiB\n"
     ]
    }
   ],
   "source": [
    "%memit q2_memory(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparación de resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Función     | Tiempo de Ejecución             | Memoria Máxima (peak) | \n",
    "|-------------|---------------------------------|-----------------------|\n",
    "| `q2_time`   | 24.3 s ± 238 ms per loop        | 1346.95 MiB           |\n",
    "| `q2_memory` | 26.6 s ± 167 ms per loop        | 120.07 MiB            |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Top 10 histórico de usuarios (username) más influyentes en función del conteo de las menciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## q3_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Desarrollo de la función"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precompilar la expresión regular para encontrar menciones\n",
    "mention_pattern = regex.compile(r'@\\w+')\n",
    "\n",
    "def extract_mentions(text: str) -> List[str]:\n",
    "    \"\"\"\n",
    "    Extrae todas las menciones (@) de un texto dado utilizando una expresión regular.\n",
    "    \n",
    "    Args:\n",
    "        text (str): El texto del cual extraer menciones.\n",
    "\n",
    "    Returns:\n",
    "        List[str]: Una lista de menciones encontradas en el texto.\n",
    "    \"\"\"\n",
    "    mentions = mention_pattern.findall(text)\n",
    "    return [mention[1:] for mention in mentions] \n",
    "\n",
    "\n",
    "def q3_time(file_path: str) -> List[Tuple[str, int]]:\n",
    "    \"\"\"\n",
    "    Procesa un archivo JSON línea por línea, analiza el contenido de los tweets\n",
    "    y devuelve una lista con los 10 usuarios más mencionados y su respectivo conteo.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): La ruta al archivo JSON que contiene los tweets. Cada línea del archivo\n",
    "                         debe ser un objeto JSON que representa un tweet.\n",
    "\n",
    "    Returns:\n",
    "        List[Tuple[str, int]]: Una lista de tuplas, donde cada tupla contiene un usuario y su conteo.\n",
    "                               La lista está ordenada por conteo en orden descendente, incluyendo solo los 10 usuarios principales.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Leer y procesar el archivo en una sola pasada para mejorar la eficiencia\n",
    "    with open(file_path, 'r') as file:\n",
    "        data = [ujson.loads(line) for line in file]\n",
    "    \n",
    "    mention_count = Counter()    \n",
    "\n",
    "    for tweet in data:\n",
    "                \n",
    "        if not validate_tweet(tweet):\n",
    "            continue\n",
    "        content = tweet.get(\"content\", \"\")\n",
    "        mentions = extract_mentions(content)\n",
    "        mention_count.update(mentions)\n",
    "\n",
    "    result = mention_count.most_common(10)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test y evaluación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Revisión de los resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('narendramodi', 2261),\n",
       " ('Kisanektamorcha', 1836),\n",
       " ('RakeshTikaitBKU', 1639),\n",
       " ('PMOIndia', 1422),\n",
       " ('RahulGandhi', 1125),\n",
       " ('GretaThunberg', 1046),\n",
       " ('RaviSinghKA', 1015),\n",
       " ('rihanna', 972),\n",
       " ('UNHumanRights', 962),\n",
       " ('meenaharris', 925)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q3_time(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Medición de tiempo promedio con su derivación estandard para 7 ejecuciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.49 s ± 67.7 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit q3_time(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Medición de la memoria usada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 1348.21 MiB, increment: 1215.17 MiB\n"
     ]
    }
   ],
   "source": [
    "%memit q3_time(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## q3_memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Desarrollo de la función"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precompilar la expresión regular para encontrar menciones\n",
    "mention_pattern = regex.compile(r'@\\w+')\n",
    "\n",
    "def extract_mentions(text: str) -> List[str]:\n",
    "    \"\"\"\n",
    "    Extrae todas las menciones (@) de un texto dado utilizando una expresión regular.\n",
    "    \n",
    "    Args:\n",
    "        text (str): El texto del cual extraer menciones.\n",
    "\n",
    "    Returns:\n",
    "        List[str]: Una lista de menciones encontradas en el texto.\n",
    "    \"\"\"\n",
    "\n",
    "    mentions = mention_pattern.findall(text)\n",
    "    return [mention[1:] for mention in mentions] \n",
    "\n",
    "def q3_memory(file_path: str) -> List[Tuple[str, int]]:\n",
    "    \"\"\"\n",
    "    Procesa un archivo JSON línea por línea, analiza el contenido de los tweets\n",
    "    y devuelve una lista con los 10 usuarios más mencionados y su respectivo conteo.\n",
    "    Esta implementación está optimizada para el uso eficiente de memoria.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): La ruta al archivo JSON que contiene los tweets. Cada línea del archivo\n",
    "                         debe ser un objeto JSON que representa un tweet.\n",
    "\n",
    "    Returns:\n",
    "        List[Tuple[str, int]]: Una lista de tuplas, donde cada tupla contiene un usuario y su conteo.\n",
    "                               La lista está ordenada por conteo en orden descendente, incluyendo solo los 10 usuarios principales.\n",
    "    \"\"\"\n",
    "    \n",
    "    mention_count = Counter()\n",
    "\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            tweet = json.loads(line)\n",
    "            if not validate_tweet(tweet):\n",
    "                continue\n",
    "            content = tweet.get(\"content\", \"\")\n",
    "            mentions = extract_mentions(content)\n",
    "            mention_count.update(mentions)\n",
    "\n",
    "    return mention_count.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test y evaluación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Revisión de los resutlados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('narendramodi', 2261),\n",
       " ('Kisanektamorcha', 1836),\n",
       " ('RakeshTikaitBKU', 1639),\n",
       " ('PMOIndia', 1422),\n",
       " ('RahulGandhi', 1125),\n",
       " ('GretaThunberg', 1046),\n",
       " ('RaviSinghKA', 1015),\n",
       " ('rihanna', 972),\n",
       " ('UNHumanRights', 962),\n",
       " ('meenaharris', 925)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q3_memory(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Medición de tiempo promedio con su derivación estandard para 7 ejecuciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.2 s ± 63 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit q3_memory(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Medición de la memoria usada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 118.32 MiB, increment: 0.00 MiB\n"
     ]
    }
   ],
   "source": [
    "%memit q3_memory(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparación de resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Función     | Tiempo de Ejecución             | Memoria Máxima (peak) | \n",
    "|-------------|---------------------------------|-----------------------|\n",
    "| `q3_time`   | 8.49 s ± 67.7 ms per loop       | 1348.21 MiB           |\n",
    "| `q3_memory` | 10.2 s ± 63 ms per loop         | 118.32 MiB            |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusiones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Debido al tamaño del archivo y limitación de recursos, es complejo optimizar el tiempo de ejecución, pero la memoria sí pudo ser optimizada de forma satisfactoria.\n",
    "\n",
    "Se trató de usar librerías simples y que no dependan de otras con el fin de poder usar el código para crear las Cloud Functions sin mayor inconveniente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Post Request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POST request was successful!\n",
      "Response: {\"status\":\"OK\",\"detail\":\"your request was received\"}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "url = \"https://advana-challenge-check-api-cr-k4hdbggvoq-uc.a.run.app/data-engineer\"\n",
    "payload = {\n",
    "    \"name\": \"Juan Diego Gallego\",\n",
    "    \"mail\": \"jgallegovillada@gmail.com\",\n",
    "    \"github_url\": \"https://github.com/juand-gv/GCPChallengeDE.git\"\n",
    "}\n",
    "\n",
    "response = requests.post(url, json=payload)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    print(\"POST request was successful!\")\n",
    "    print(\"Response:\", response.text)\n",
    "else:\n",
    "    print(\"POST request failed with status code:\", response.status_code)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "challengeGlobant",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
